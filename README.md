# spotify_update_checker - Spotify Data Pipeline

# ğŸµ Spotify Data Pipeline

## ğŸ“Œ å°ˆæ¡ˆç°¡ä»‹
é€™å€‹å°ˆæ¡ˆçš„ç›®çš„æ˜¯è¨˜éŒ„ä½¿ç”¨è€…åœ¨ Spotify ä¸Šçš„éŸ³æ¨‚è†è½è¡Œç‚ºï¼Œä¸¦ä½œç‚ºæœªä¾†æ¨è–¦æ­Œæ›²çš„åƒè€ƒä¾æ“šã€‚åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š
1. **è¨˜éŒ„æœ€è¿‘æ’­æ”¾çš„æ­Œæ›²**ï¼šç”±æ–¼ Spotify API é™åˆ¶æ¯æ¬¡æœ€å¤šåªèƒ½ç²å– 50 é¦–æ­Œæ›²ï¼Œå› æ­¤éœ€è¦é »ç¹ä¸²æ¥ API ä¾†è¨˜éŒ„å®Œæ•´çš„è†è½æ­·å²ã€‚
2. **æ¯æ—¥è¨˜éŒ„ä½¿ç”¨è€…é—œæ³¨çš„æ¼”å¥è€…**ï¼šç¢ºä¿æœ€æ–°çš„æ¼”å¥è€…æ¸…å–®åŒæ­¥åˆ°è³‡æ–™åº«ã€‚
3. **æ­Œæ›²è³‡è¨Šè¨˜éŒ„èˆ‡å»é‡**ï¼šæ­Œæ›²è³‡è¨Šï¼ˆå¦‚æ›²ç›®ç‰¹æ€§ã€ç™¼è¡¨æ™‚é–“ã€æ¼”å¥è€…ç­‰ï¼‰ä¸æœƒç«‹å³å„²å­˜ï¼Œè€Œæ˜¯ç­‰å¾…ç´¯ç©è¶³å¤ æ•¸é‡å¾Œä¸€æ¬¡æ€§å»é‡å„²å­˜ã€‚

---

## ğŸ”„ **è³‡æ–™æµæ¶æ§‹**
å°ˆæ¡ˆä½¿ç”¨ **Apache Airflow** ä¾†ç®¡ç†è³‡æ–™ç®¡é“ï¼Œä¸¦é€é **Spotify API** ç²å–æ•¸æ“šï¼Œæœ€å¾Œå°‡è™•ç†å¾Œçš„æ•¸æ“šå­˜å…¥ **AWS S3 èˆ‡ MySQL**ã€‚è³‡æ–™æµå¦‚ä¸‹ï¼š

### **ğŸ“Œ æ¯å…©å°æ™‚åŸ·è¡Œ (`spotify_bihourly_download_dag.py`)**
1. **åˆ·æ–° Spotify Access Token** â†’ é€é `refresh_access_token()` ç²å–æ–°çš„å­˜å–æ¬Šæ–ã€‚
2. **å–å¾—æœ€è¿‘æ’­æ”¾çš„æ­Œæ›² (`get_recently_played()`)**  
   - å–å¾—å¾Œçš„ JSON æª”æ¡ˆæœƒä¸Šå‚³è‡³ **AWS S3** (`recently_played/YYYYMMDDHH.json`)ã€‚

---

### **ğŸ“Œ æ¯æ—¥åŸ·è¡Œ (`spotify_daily_download_dag.py`)**
1. **åˆ·æ–° Spotify Access Token**
2. **å–å¾—ä½¿ç”¨è€…é—œæ³¨çš„æ¼”å¥è€… (`get_following_artist()`)**  
   - ç²å–å®Œæ•´çš„è¿½è¹¤æ¸…å–®ï¼Œä¸¦ä¸Šå‚³è‡³ **AWS S3** (`following_artists/YYYYMMDDHH.json`)ã€‚

---

### **ğŸ“Œ æ¯æ—¥æ•¸æ“šè™•ç† (`spotify_daily_data_pipeline.py`)**
1. **è™•ç†æœ€è¿‘æ’­æ”¾çš„æ­Œæ›² (`process_recently_played()`)**
   - è®€å– `recently_played/YYYYMMDDHH.json`ï¼Œè§£æå¾Œå­˜å…¥ **MySQL**ã€‚
   - ç¢ºä¿ä¸é‡è¤‡å­˜å…¥ç›¸åŒçš„æ­Œæ›²ç´€éŒ„ã€‚
2. **è™•ç†ä½¿ç”¨è€…é—œæ³¨çš„æ¼”å¥è€… (`process_following_artists()`)**
   - è®€å– `following_artists/YYYYMMDDHH.json`ï¼Œè§£æå¾Œå­˜å…¥ **MySQL**ã€‚

---

## âš™ï¸ **ä½¿ç”¨æ–¹å¼**

### 1ï¸âƒ£ å®‰è£ä¾è³´å¥—ä»¶
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ è¨­ç½® DAG æª”æ¡ˆ
è«‹å°‡ä»¥ä¸‹æª”æ¡ˆç§»å‹•åˆ° `dags/` è³‡æ–™å¤¾ï¼š
```
spotify_bihourly_download_dag.py
spotify_daily_data_pipeline.py
spotify_daily_download_dag.py
utils/
```

### 3ï¸âƒ£ å•Ÿå‹• Airflow
```bash
airflow scheduler
airflow webserver -p 8080
```

### 4ï¸âƒ£ è¨­å®šé€£ç·šè³‡è¨Š
è«‹æ ¹æ“šä½ çš„ç’°å¢ƒé…ç½®ä»¥ä¸‹é€£ç·šè³‡è¨Šï¼š
- **AWS S3 å­˜å–è³‡è¨Š**ï¼š`aws_access_key.txt`
- **MySQL è³‡æ–™åº«é€£ç·šè³‡è¨Š**ï¼š`db_access_key.txt`
- **Spotify API èªè­‰è³‡è¨Š**ï¼š
  - `spotify_client_info.txt`
  - `tokens.json`

DAG çš„è©³ç´°åŠŸèƒ½èˆ‡æµç¨‹å¯åƒè€ƒ `dags/` å…§çš„ Python æª”æ¡ˆã€‚

---

# ğŸµ Spotify Data Pipeline (English Version)

## ğŸ“Œ Project Overview
This project is designed to track users' listening behavior on Spotify and use it for future song recommendations. The key features include:
1. **Tracking recently played songs**: Since the Spotify API only allows fetching the last 50 played songs, the system needs to fetch data frequently.
2. **Daily tracking of followed artists**: Ensures that the user's followed artist list is up-to-date.
3. **Recording and deduplicating song metadata**: Instead of storing song metadata immediately, the system waits until a sufficient amount of data is collected before processing and avoiding duplicates.

---

## ğŸ”„ **Data Flow Architecture**
The project uses **Apache Airflow** to manage the data pipeline. Data is fetched from **Spotify API**, stored in **AWS S3**, and processed into **MySQL**. The workflow is as follows:

### **ğŸ“Œ Every 2 Hours (`spotify_bihourly_download_dag.py`)**
1. **Refresh Spotify Access Token** â†’ Uses `refresh_access_token()` to obtain a new token.
2. **Fetch Recently Played Songs (`get_recently_played()`)**
   - The data is uploaded to **AWS S3** (`recently_played/YYYYMMDDHH.json`).

---

### **ğŸ“Œ Daily Data Collection (`spotify_daily_download_dag.py`)**
1. **Refresh Spotify Access Token**
2. **Fetch Followed Artists (`get_following_artist()`)**
   - The data is uploaded to **AWS S3** (`following_artists/YYYYMMDDHH.json`).

---

### **ğŸ“Œ Daily Data Processing (`spotify_daily_data_pipeline.py`)**
1. **Process Recently Played Songs (`process_recently_played()`)**
   - Reads `recently_played/YYYYMMDDHH.json`, processes the data, and inserts it into **MySQL**.
   - Ensures that duplicate records are not stored.
2. **Process Followed Artists (`process_following_artists()`)**
   - Reads `following_artists/YYYYMMDDHH.json`, processes the data, and inserts it into **MySQL**.

---

## âš™ï¸ **Usage**

### 1ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Move DAG Files to the `dags/` Directory:
```
spotify_bihourly_download_dag.py
spotify_daily_data_pipeline.py
spotify_daily_download_dag.py
utils/
```

### 3ï¸âƒ£ Start Airflow
```bash
airflow scheduler
airflow webserver -p 8080
```

### 4ï¸âƒ£ Configure Connection Credentials:
- **AWS S3 access**: `aws_access_key.txt`
- **MySQL database credentials**: `db_access_key.txt`
- **Spotify API credentials**:
  - `spotify_client_info.txt`
  - `tokens.json`

For more details on DAG functionalities, refer to the Python files in the `dags/` folder.
